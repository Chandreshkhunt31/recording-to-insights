# If set, OpenAI will be used for both transcription + LLM.
OPENAI_API_KEY=

# Model choices (defaults are fine).
OPENAI_TRANSCRIPTION_MODEL=whisper-1
OPENAI_CHAT_MODEL=gpt-4o-mini

# Local input folder (audio files you place in the repo)
DATA_DIR=./data

# Local persistence
OUTPUT_DIR=./outputs


